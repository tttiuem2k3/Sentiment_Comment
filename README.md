# âœ¨ PhÃ¢n tÃ­ch Sáº¯c ThÃ¡i Cáº£m XÃºc BÃ¬nh Luáº­n TrÃªn SÃ n ThÆ°Æ¡ng Máº¡i Äiá»‡n Tá»­ âœ¨

## ğŸ’¡ Giá»›i Thiá»‡u Chung
Trong bá»‘i cáº£nh phÃ¡t triá»ƒn máº¡nh máº½ cá»§a cÃ¡c sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­, cÃ¡c bÃ¬nh luáº­n tá»« ngÆ°á»i tiÃªu dÃ¹ng trá»Ÿ thÃ nh nguá»“n thÃ´ng tin quan trá»ng giÃºp ngÆ°á»i mua Ä‘á»“ phÃ¢n tÃ­ch sáº£n pháº©m vÃ  nhÃ  bÃ¡n hÃ ng cáº£i thiá»‡n dá»‹ch vá»¥.

Dá»± Ã¡n nÃ y nháº±m má»¥c tiÃªu giÃºp phÃ¢n tÃ­ch nhanh cÃ¡c bÃ¬nh luáº­n vÃ  tÃ¬m hiá»ƒu xem nháº­n Ä‘á»‹nh cá»§a ngÆ°á»i dÃ¹ng lÃ  tÃ­ch cá»±c hay tiÃªu cá»±c tá»« Ä‘Ã³ Ä‘Æ°a ra Ä‘Æ°á»£c nháº­n xÃ©t tá»•ng thá»ƒ lÃ  sáº£n pháº©m cÃ³ nÃªn mua hay lÃ  khÃ´ng!

**Sentiment Analysis** lÃ  má»™t ká»¹ thuáº­t trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn **(NLP)** dÃ¹ng Ä‘á»ƒ xÃ¡c Ä‘á»‹nh vÃ  phÃ¢n loáº¡i cáº£m xÃºc (tÃ­ch cá»±c, tiÃªu cá»±c) cá»§a vÄƒn báº£n. Äá» tÃ i nÃ y táº­p trung xÃ¢y dá»±ng má»™t há»‡ thá»‘ng phÃ¢n tÃ­ch cáº£m xÃºc hiá»‡u quáº£, Ã¡p dá»¥ng mÃ´ hÃ¬nh **PhoBERT** káº¿t há»£p vá»›i **CNN** vÃ  **BiLSTM** Ä‘á»ƒ khai thÃ¡c tá»‘i Æ°u Ä‘áº·c trÆ°ng ngá»¯ nghÄ©a vÃ  ngá»¯ cáº£nh trong bÃ¬nh luáº­n tiáº¿ng Viá»‡t. NgoÃ i ra cÃ²n triá»ƒn khai mÃ´ hÃ¬nh **ELECTRA-BASE** nháº±m Ä‘Ã¡nh giÃ¡ xem mÃ´ hÃ¬nh trÃªn Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn Embedding cá»§a PhoBert Ä‘Ã£ tá»›i háº¡n vá»›i táº­p dá»¯ liá»‡u hay chÆ°a, triá»ƒn khai mÃ´ hÃ¬nh ELECTRA-Base loáº¡i bá» hoÃ n toÃ n cÃ¡c lá»›p tÃ¹y chá»‰nh (CNN, BiLSTM, Attention) vÃ  dá»±a vÃ o kiáº¿n trÃºc transformer cá»§a Electra Ä‘á»ƒ xem Ä‘á»™ chÃ­nh xÃ¡c cÃ³ Ä‘Æ°á»£c cáº£i thiá»‡n hay khÃ´ng, khÃ¡m phÃ¡ kháº£ nÄƒng cá»§a ELECTRA trong xá»­ lÃ½ ngÃ´n ngá»¯ tiáº¿ng Viá»‡t. NghiÃªn cá»©u há»©a háº¹n mang láº¡i giÃ¡ trá»‹ á»©ng dá»¥ng cao vÃ  Ä‘Ã³ng gÃ³p vÃ o viá»‡c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn cho tiáº¿ng Viá»‡t.

---

## ğŸ› ï¸ Chá»©c nÄƒng chÃ­nh
- **ğŸ” PhÃ¢n loáº¡i tin giáº£**: Nháº­n Ä‘áº§u vÃ o lÃ  vÄƒn báº£n, tráº£ vá» nhÃ£n "Tháº­t"/"Giáº£" kÃ¨m xÃ¡c suáº¥t.
- **ğŸ“Š Giao diá»‡n trá»±c quan**: Biá»ƒu Ä‘á»“ pie chart.

---

## :tv: Demo
![Demo](demo1.gif)
- Xem DEMO Ä‘áº§y Ä‘á»§ táº¡i Ä‘Ã¢y: https://www.youtube.com/watch?v=HQ2c8JY_TXI&t=25sz
  
---

## Tá»•ng quan há»‡ thá»‘ng vÃ  quy trÃ¬nh thá»±c hiá»‡n 

 ![SÆ¡ Ä‘á»“ tá»•ng quan há»‡ thá»‘ng](./Images/img1.JPG)
 
 ![SÆ¡ Ä‘á»“ qui trÃ¬nh thá»±c hiá»‡n](./Images/img2.JPG)
 
---

## ğŸ“‚ Nguá»“n dá»¯ liá»‡u
- **ğŸ“° Dá»¯ liá»‡u**: Thu tháº­p tá»« cÃ¡c bÃ¬nh luáº­n cá»§a sáº£n pháº©m tá»« cÃ¡c sÃ n thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­ nhÆ°: Shopee, Lazada, Tiki, Sendo,...
- **ğŸ“Š Cáº¥u trÃºc dá»¯ liá»‡u**: Bao gá»“m  ná»™i dung cá»§a bÃ¬nh luáº­n, nhÃ£n (TÃ­ch cá»±c/TiÃªu cá»±c).
---

## ğŸ”„ QuÃ¡ trÃ¬nh thu tháº­p vÃ  xá»­ lÃ½ dá»¯ liá»‡u
1. **ğŸ—‚ï¸ Thu tháº­p dá»¯ liá»‡u**:
   - Sá»­ dá»¥ng cÃ¡c thÆ° viá»‡n nhÆ° Selenium, BeautifulSoup, Requests,.. Ä‘á»ƒ thu tháº­p dá»¯ liá»‡u lÃ  cÃ¡c bÃ i bÃ¡o tá»« nguá»“n dá»¯ liá»‡u theo cáº¥u trÃºc dá»¯ liá»‡u.
   - GÃ¡n nhÃ£n cho dá»¯ liá»‡u: Sau bÆ°á»›c thu tháº­p dá»¯ liá»‡u bÃ¬nh luáº­n lÃ  gÃ¡n nhÃ£n (tÃ­ch cá»±c: 0 , tiÃªu cá»±c: 1) cho cÃ¡c bÃ¬nh luáº­n dá»±a theo tiÃªu chÃ­:
      * Äá»ƒ Ä‘Ã¡nh giÃ¡ má»™t nhÃ£n cá»§a bÃ¬nh luáº­n thÃ¬ trÆ°á»›c háº¿t pháº£i Æ°u tiÃªn Ä‘áº¿n cháº¥t lÆ°á»£ng cá»§a sáº£n pháº©m, vÃ­ dá»¥:
         
            + Sáº£n pháº©m ráº¥t Ä‘áº¹p, giao hÃ ng nhanh - NhÃ£n tÃ­ch cá»±c: 0
            + Sáº£n pháº©m kÃ©m cháº¥t lÆ°á»£ng, giao hÃ ng nhanh - NhÃ£n tiÃªu cá»±c: 1
      * CÃ¡c bÃ¬nh luáº­n trung láº­p thÃ¬ pháº£i dá»±a vÃ o má»©c Ä‘á»™ Ä‘Ã¡nh giÃ¡ giÃ¡ sáº£n pháº©m Ä‘á»ƒ gÃ¡n nhÃ£n,vÃ­ dá»¥: 
        
            + Sáº£n pháº©m tá»‘t, giao hÃ ng hÆ¡i cháº­m - NhÃ£n tÃ­ch cá»±c: 0
            + Sáº£n pháº©m tá»‘t, giao hÃ ng cháº­m, Ä‘Ã³ng gÃ³i sáº£n pháº©m kÃ©m - NhÃ£n tiÃªu cá»±c: 1
   - Tham kháº£o code á»Ÿ thÆ° má»¥c [Crawl](./DATA/Crawl)
2. **ğŸ§¹ Tiá»n xá»­ lÃ½**:
   - Chuáº©n hÃ³a vÄƒn báº£n (chuyá»ƒn chá»¯ thÆ°á»ng, xÃ³a kÃ½ tá»± Ä‘áº·c biá»‡t).
   - TÃ¡ch tá»« tiáº¿ng Viá»‡t (word_segmentation): [`NlpHUST/vi-word-segmentation`](https://huggingface.co/NlpHUST/vi-word-segmentation)
   - Loáº¡i bá» stopwords vÃ  cÃ¢n báº±ng dá»¯ liá»‡u.
     
   ![Qui trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u](./Images/img3.JPG)
3. **ğŸ“Š Thá»‘ng kÃª dá»¯ liá»‡u**:
   
   | Loáº¡i bÃ¬nh luáº­n | Sá»‘ lÆ°á»£ng | Tá»· lá»‡ |
   |----------------|----------|-------|
   | ğŸ“° TÃ­ch cá»±c   | 17,312   | 50.2% |
   | ğŸ“› TiÃªu cá»±c   | 17,156   | 49.8% |

4. **ğŸ“‚ PhÃ¢n chia táº­p dá»¯ liá»‡u huáº¥n luyá»‡n**:
   - **Train**: 70% (24.127 máº«u)
   - **Validation**: 15% (5.170 máº«u)
   - **Test**: 15% (5.171 máº«u)

---

## ğŸš€ ELECTRA-Base: Giá»›i thiá»‡u vÃ  Sá»©c máº¡nh
### ğŸŒŸ Tá»•ng quan
**ELECTRA** (Efficiently Learning an Encoder that Classifies Token Replacements Accurately) lÃ  mÃ´ hÃ¬nh NLP sá»­ dá»¥ng cÆ¡ cháº¿ **Replaced Token Detection**:
- **Generator**: Táº¡o token giáº£ thay tháº¿ ngáº«u nhiÃªn.
- **Discriminator**: PhÃ¡t hiá»‡n token bá»‹ thay tháº¿, tá»‘i Æ°u hÃ³a viá»‡c há»c toÃ n bá»™ Ä‘áº§u vÃ o.
  
![cÆ¡ cháº¿ electra](./Images/img4.jpg)
### ğŸ’ª Æ¯u Ä‘iá»ƒm vÆ°á»£t trá»™i
| Æ¯u Ä‘iá»ƒm                  | Hiá»‡u quáº£                                                                 |
|--------------------------|--------------------------------------------------------------------------|
| **ğŸ’» Tiáº¿t kiá»‡m tÃ i nguyÃªn**     | Chá»‰ cáº§n 25% tÃ i nguyÃªn so vá»›i BERT/RoBERTa                               |
| **ğŸ“œ Xá»­ lÃ½ vÄƒn báº£n dÃ i**        | Ãp dá»¥ng **Sliding Window** (512 tokens/window) vá»›i overlap 128 tokens    |
| **ğŸ¯ Äá»™ chÃ­nh xÃ¡c cao**         | F1-score Ä‘áº¡t **99%** trÃªn táº­p test                                       |
| **ğŸ§  TÃ­ch há»£p Attention**       | ThÃªm Multihead Attention Ä‘á»ƒ táº­p trung vÃ o tá»« khÃ³a quan trá»ng            |

### ğŸ”§ Cáº£i tiáº¿n trong dá»± Ã¡n
1. **ğŸ“œ Xá»­ lÃ½ vÄƒn báº£n dÃ i**:
   - Chia vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n 512 tokens, káº¿t há»£p ká»¹ thuáº­t overlap - cá»­a sá»• trÆ°á»£t vá»›i Ä‘á»™ trÆ°á»£t lÃ  128 tokens.
   - DÃ¹ng voting tá»« cÃ¡c Ä‘oáº¡n Ä‘á»ƒ quyáº¿t Ä‘á»‹nh nhÃ£n cuá»‘i cÃ¹ng.
2. **âš™ï¸ NÃ¢ng cáº¥p kiáº¿n trÃºc**:
   - ThÃªm lá»›p **MultiheadAttention** vÃ  **LayerNorm**.
   - TÃ­ch há»£p Fully Connected layers Ä‘á»ƒ tá»‘i Æ°u biá»ƒu diá»…n Ä‘áº·c trÆ°ng.
     
![cáº£i tiáº¿n mÃ´ hÃ¬nh electra](./Images/img5.jpg)

### ğŸš€ Qui trÃ¬nh huáº¥n luyá»‡n
1. **ğŸ› ï¸ Cáº¥u hÃ¬nh huáº¥n luyá»‡n:**

| Epochs      | BATH_SIZE | OPTIMIZER | DROPOUT |LEARNING_RATE|NUM_CLASSES| 
|-------------|-----------|-----------|---------|-------------|-----------| 
|    **4**    |  **48**   |**AdamW**  | **0.3** | **5e-5 -> 1e-5**|**2**| 

2. **ğŸ—ƒï¸ Qui trÃ¬nh huáº¥n luyá»‡n:**

![qui trÃ¬nh huáº¥n luyá»‡n](./Images/img6.jpg)


## ğŸ“ˆ Káº¿t quáº£
| Model       | Accuracy | F1-score | Recall |
|-------------|----------|----------|--------|
| ELECTRA-Base| **99%**  | **99%**  | **99%**|

![Ma tráº­n nháº§m láº«n](./Images/img9.jpg)

---
## âš–ï¸ So sÃ¡nh káº¿t quáº£ vá»›i Transformer-XL vÃ  PhoBERT

DÆ°á»›i Ä‘Ã¢y lÃ  báº£ng so sÃ¡nh káº¿t quáº£ giá»¯a **ELECTRA-Base**, **Transformer-XL**, vÃ  **PhoBERT** trÃªn táº­p dá»¯ liá»‡u test:

| Model           | Accuracy | F1-score | Recall | Parameters |
|-----------------|----------|----------|--------|------------|
| **ELECTRA-Base**| **99%**  | **99%**  | **99%**| 109M       |
| Transformer-XL  | 94%      | 94%      | 94%    | 191M       |
| PhoBERT         | 93%      | 93%      | 93%    | 135M       |

### ğŸ“Š Biá»ƒu Ä‘á»“ so sÃ¡nh
![Biá»ƒu Ä‘á»“ so sÃ¡nh Ä‘á»™ máº¥t mÃ¡t](./Images/img7.jpg)

![Biá»ƒu Ä‘á»“ so sÃ¡nh Ä‘á»™ chÃ­nh xÃ¡c](./Images/img8.jpg)

### ğŸ“ Nháº­n xÃ©t
- **ELECTRA-Base** cho káº¿t quáº£ **vÆ°á»£t trá»™i** so vá»›i Transformer-XL vÃ  PhoBERT, Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c **99%**.
- **Transformer-XL** vÃ  **PhoBERT** cÅ©ng cho káº¿t quáº£ tá»‘t, nhÆ°ng Ä‘á»™ chÃ­nh xÃ¡c tháº¥p hÆ¡n (94% vÃ  93%).
- **ELECTRA-Base** sá»­ dá»¥ng Ã­t tham sá»‘ hÆ¡n (109M) so vá»›i Transformer-XL (191M) vÃ  PhoBERT (135M), giÃºp tiáº¿t kiá»‡m tÃ i nguyÃªn tÃ­nh toÃ¡n.

---
## ğŸ”® HÆ°á»›ng phÃ¡t triá»ƒn
- **ğŸŒ Má»Ÿ rá»™ng sang Ä‘a ngÃ´n ngá»¯** (tiáº¿ng Anh, Trung).
- **ğŸ–¼ï¸ TÃ­ch há»£p phÃ¢n tÃ­ch hÃ¬nh áº£nh/video** báº±ng CNN.
- **ğŸŒ XÃ¢y dá»±ng extension trÃ¬nh duyá»‡t** Ä‘á»ƒ quÃ©t tin giáº£ real-time.

---

## ğŸ› ï¸ CÃ i Ä‘áº·t
### Táº£i code:
```bash
git clone https://github.com/your-repo/fake-news-detection
cd fake-news-detection
pip install -r requirements.txt
```
### Huáº¥n luyá»‡n mÃ´ hÃ¬nh:
- Huáº¥n luyá»‡n mÃ´ hÃ¬nh dá»±a trÃªn bá»™ data: [`DATA.rar`](./DATA/DATA.rar)
- Tham khoáº£n code huáº¥n luyá»‡n mÃ´ hÃ¬nh: [`CODE`](./CODE)
### Cháº¡y á»©ng dá»¥ng:
Run python [`App.py`](./APP/App.py)

---

##  ğŸ“ LiÃªn há»‡
- ğŸ‘¥ Linkedin: https://www.linkedin.com/in/thinh-tran-04122k3/

- ğŸ“§ Email: tttiuem2k3@gmail.com
